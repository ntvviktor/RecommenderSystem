{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae1ae260-59d6-43b6-bf3b-c28bfca8b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from CDAE import CDAE\n",
    "from Dataset import Dataset\n",
    "from Evaluator import Evaluator\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73dda38",
   "metadata": {},
   "source": [
    "The model is built as follow:\n",
    "1. The encoder Layer has the shape of `total_number_of_items` $\\times$ `the_hidden_dimension`\n",
    "\n",
    "$$\n",
    "z_u = h(W^{\\intercal}\\widetilde{y}_u + V_u + b)\n",
    "$$\n",
    "\n",
    "- $W$ weight matrix `total_number_of_items` $\\times$ `the_hidden_dimension`\n",
    "- $\\widetilde{y}_u$ the user-rating input matrix with the shape of `batch_size` $\\times$ `total_number_of_items`\n",
    "- $V_u$ user-specific vector, each user's id will be uniquely embedded with its corresponding vector and contribute to the fomula itself, which serve the purpose of improving performance metrics for the user.\n",
    "\n",
    "2. The hidden layer (50 $\\times$ 50)\n",
    "3. The decoder layer will has the shape of `the_hidden_dimension` $\\times$ `the_total_number_of item`\n",
    "\n",
    "\n",
    "**The model face two major problems:**\n",
    "\n",
    "- Cold start: new user has not yet been trained in the model, so there will not be a good recommendation engine at first for new user. One solution for this is to recommend the related items for this user at first, before feeding the engine.\n",
    "- During splitting dataset, the data utility will randomly split at some predefined percentage, hence, the data will receive the NA values rating at test set or train set. This problem will be overcome by setting threshold for at least 4 ratings different item ratings per user.\n",
    "\n",
    "Another problem might be that this autoencoder model only consider user-item interaction (or called implicit feedback) such as 0, 1 but not a rating scale such as 1-5, since the performance on those two rating system would not be different. However, the advantages of this would be based on the assumption of user will rarely rate the item but click to view, this can be count as interested and put rating at 1 on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de120fe",
   "metadata": {},
   "source": [
    "#### Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c22e1ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9296</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2318</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        1      258       5\n",
       "1        2     4081       4\n",
       "2        2      260       5\n",
       "3        2     9296       5\n",
       "4        2     2318       3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"goodread_books/ratings.csv\", engine=\"python\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b7045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5976479, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed9915d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5976479, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.rename(columns={\"user_id\": \"user\", \"book_id\": \"item\", \"rating\": \"rating\"})\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255bc47",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "- Remove ratings that equal to zero\n",
    "- Set threshold and scale down dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c57c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9296</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2318</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     1   258       5\n",
       "1     2  4081       4\n",
       "2     2   260       5\n",
       "3     2  9296       5\n",
       "4     2  2318       3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_rating_row_dix = data[data[\"rating\"] == 0].index\n",
    "data = data.drop(zero_rating_row_dix)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4098443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5976479, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f403f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select user IDs with more than 20 book ratings\n",
    "min_ratings_threshold = 20\n",
    "\n",
    "# Count book ratings per user\n",
    "num_ratings_per_user = data.groupby('user')['rating'].count()\n",
    "\n",
    "# Filter users with more than the minimum threshold\n",
    "knowledgeable_user_ids = num_ratings_per_user[num_ratings_per_user > min_ratings_threshold].index\n",
    "knowledgeable_user_ratings = data[data['user'].isin(knowledgeable_user_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98cf720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5976440, 3)\n",
      "   user  item  rating\n",
      "0     1   258       5\n",
      "1     2  4081       4\n",
      "2     2   260       5\n",
      "3     2  9296       5\n",
      "4     2  2318       3\n"
     ]
    }
   ],
   "source": [
    "print(knowledgeable_user_ratings.shape)\n",
    "print(knowledgeable_user_ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b45ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(knowledgeable_user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd11306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ratings_count_threshold = 8\n",
    "rating_counts= knowledgeable_user_ratings.groupby('item').count()['rating']\n",
    "popular_books = rating_counts[rating_counts >= min_ratings_count_threshold].index\n",
    "final_ratings =  knowledgeable_user_ratings[knowledgeable_user_ratings['item'].isin(popular_books)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731e29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(final_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8078770",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group = final_ratings.groupby('user')\n",
    "for i, group in data_group:\n",
    "    num_items_user = len(group)\n",
    "    if num_items_user <= 4:\n",
    "        final_ratings = final_ratings.drop(final_ratings[final_ratings[\"user\"] == i].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8501c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial users: 53422, items: 10000\n"
     ]
    }
   ],
   "source": [
    "num_users = len(pd.unique(final_ratings.user))\n",
    "num_items = len(pd.unique(final_ratings.item))\n",
    "print('Initial users: {}, items: {}'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1024d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5976440, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00d740f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9296</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2318</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     1   258       5\n",
       "1     2  4081       4\n",
       "2     2   260       5\n",
       "3     2  9296       5\n",
       "4     2  2318       3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = export_data.drop([\"item\"], axis=1)\n",
    "# df = df.rename(columns={\"user\": \"user\", \"rating\": \"rating\", \"new_items_id\": \"item\"})\n",
    "# df = df.reindex(columns=[\"user\", \"item\", \"rating\"])\n",
    "df = final_ratings.copy()\n",
    "df.to_csv(\"books/edited_ratings.csv\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4710ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "data_group = df.groupby(\"user\")\n",
    "counter = 0\n",
    "for _, group in data_group:\n",
    "    num_items_user = len(group)\n",
    "    if num_items_user == 1:\n",
    "        counter += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390e9ec-3c80-4a9c-815e-d05fb05ee52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "data_path = \"books/edited_ratings.csv\"\n",
    "train_ratio = 0.8\n",
    "hidden_dim = 50\n",
    "num_epochs = 200\n",
    "batch_size = 512\n",
    "testing_batch_size = 512\n",
    "learning_rate = 0.01\n",
    "early_stop = True\n",
    "patience = 50\n",
    "top_k = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82450fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess start...\n",
      "Initial users: 53422, items: 10000\n",
      "Assign new user id from 0..n\n",
      "Assign new item id from 0..n\n",
      "Split data into training set and test set\n",
      "# zero train, test: 0, 0\n",
      "Preprocess finished.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "dataset = Dataset(\n",
    "    data_path=data_path,\n",
    "    save_path=\"training.json\",\n",
    "    sep=\"\\t\",\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d79ba2-2f15-47e6-ba19-19af0ed2a193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total users': 53422,\n",
       " 'Total items': 10000,\n",
       " 'Total ratings': 5976440,\n",
       " 'Sparsity ratio': 98.8812773763618,\n",
       " 'Min/Max/Avg. ratings per users': [21, 200, 111.87226236382016],\n",
       " 'Number of train users': 53422,\n",
       " 'Number of train ratings': 4759728,\n",
       " 'Number of test users': 53422,\n",
       " 'Number of test ratings': 1216712}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.obtain_data_statistic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d90fc49",
   "metadata": {},
   "source": [
    "The rating of 1 indicate the interaction between user and item that represent in the matrix. During training time, it will take 80% of each user's rating and put it into a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33bfa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pos, eval_target = dataset.eval_data()\n",
    "item_popularity = dataset.item_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13399050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDAE(\n",
      "  (user_embedding): Embedding(53422, 50)\n",
      "  (encoder): Linear(in_features=10000, out_features=50, bias=True)\n",
      "  (decoder): Linear(in_features=50, out_features=10000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(eval_pos, eval_target, item_popularity, top_k)\n",
    "model = CDAE(num_users=dataset.num_users, \n",
    "            num_items=dataset.num_items,\n",
    "            hidden_dim=hidden_dim)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3ef1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1/200, 17.31, 6.47 loss = 41852880.00, Prec@10=0.0730 Recall@10=0.0732 NDCG@10=0.0754 Nov@10=2.9455 Gini-D=0.1157\n",
      "Training epoch 2/200, 15.73, 6.25 loss = 41097316.00, Prec@10=0.0790 Recall@10=0.0793 NDCG@10=0.0809 Nov@10=3.6707 Gini-D=0.2073\n",
      "Training epoch 3/200, 16.29, 6.49 loss = 40867560.00, Prec@10=0.0818 Recall@10=0.0821 NDCG@10=0.0840 Nov@10=3.9732 Gini-D=0.2351\n",
      "Training epoch 4/200, 15.76, 6.04 loss = 40730756.00, Prec@10=0.0843 Recall@10=0.0845 NDCG@10=0.0867 Nov@10=4.0046 Gini-D=0.2196\n",
      "Training epoch 5/200, 15.63, 6.01 loss = 40638116.00, Prec@10=0.0867 Recall@10=0.0869 NDCG@10=0.0895 Nov@10=3.9921 Gini-D=0.2075\n",
      "Training epoch 6/200, 16.48, 6.28 loss = 40571900.00, Prec@10=0.0876 Recall@10=0.0878 NDCG@10=0.0903 Nov@10=3.9845 Gini-D=0.1933\n",
      "Training epoch 7/200, 16.87, 6.32 loss = 40524408.00, Prec@10=0.0886 Recall@10=0.0889 NDCG@10=0.0912 Nov@10=3.9592 Gini-D=0.1894\n",
      "Training epoch 8/200, 16.64, 6.29 loss = 40487632.00, Prec@10=0.0898 Recall@10=0.0901 NDCG@10=0.0921 Nov@10=3.9425 Gini-D=0.1809\n",
      "Training epoch 9/200, 16.43, 6.21 loss = 40457108.00, Prec@10=0.0905 Recall@10=0.0908 NDCG@10=0.0926 Nov@10=3.9168 Gini-D=0.1729\n",
      "Training epoch 10/200, 16.06, 6.14 loss = 40430908.00, Prec@10=0.0907 Recall@10=0.0910 NDCG@10=0.0928 Nov@10=3.9061 Gini-D=0.1712\n",
      "Training epoch 11/200, 17.68, 6.52 loss = 40408188.00, Prec@10=0.0907 Recall@10=0.0910 NDCG@10=0.0924 Nov@10=3.8800 Gini-D=0.1690\n",
      "Training epoch 12/200, 16.95, 6.18 loss = 40389288.00, Prec@10=0.0900 Recall@10=0.0903 NDCG@10=0.0916 Nov@10=3.8647 Gini-D=0.1674\n",
      "Training epoch 13/200, 17.25, 6.62 loss = 40371908.00, Prec@10=0.0894 Recall@10=0.0897 NDCG@10=0.0905 Nov@10=3.8513 Gini-D=0.1654\n",
      "Training epoch 14/200, 16.00, 6.59 loss = 40356248.00, Prec@10=0.0891 Recall@10=0.0894 NDCG@10=0.0903 Nov@10=3.8345 Gini-D=0.1638\n",
      "Training epoch 15/200, 15.92, 6.09 loss = 40342912.00, Prec@10=0.0883 Recall@10=0.0885 NDCG@10=0.0894 Nov@10=3.8229 Gini-D=0.1606\n",
      "Training epoch 16/200, 15.81, 6.28 loss = 40329608.00, Prec@10=0.0877 Recall@10=0.0879 NDCG@10=0.0885 Nov@10=3.8068 Gini-D=0.1591\n",
      "Training epoch 17/200, 15.70, 6.21 loss = 40316628.00, Prec@10=0.0871 Recall@10=0.0874 NDCG@10=0.0880 Nov@10=3.7983 Gini-D=0.1565\n",
      "Training epoch 18/200, 15.89, 6.25 loss = 40305660.00, Prec@10=0.0859 Recall@10=0.0862 NDCG@10=0.0864 Nov@10=3.8007 Gini-D=0.1577\n",
      "Training epoch 19/200, 15.23, 6.06 loss = 40294088.00, Prec@10=0.0851 Recall@10=0.0854 NDCG@10=0.0858 Nov@10=3.7939 Gini-D=0.1557\n",
      "Training epoch 20/200, 15.94, 6.35 loss = 40283720.00, Prec@10=0.0851 Recall@10=0.0854 NDCG@10=0.0855 Nov@10=3.7822 Gini-D=0.1547\n",
      "Training epoch 21/200, 15.84, 6.32 loss = 40274292.00, Prec@10=0.0838 Recall@10=0.0841 NDCG@10=0.0840 Nov@10=3.7759 Gini-D=0.1524\n",
      "Training epoch 22/200, 15.69, 6.36 loss = 40263336.00, Prec@10=0.0834 Recall@10=0.0837 NDCG@10=0.0839 Nov@10=3.7725 Gini-D=0.1515\n",
      "Training epoch 23/200, 15.77, 6.26 loss = 40254536.00, Prec@10=0.0824 Recall@10=0.0828 NDCG@10=0.0830 Nov@10=3.7863 Gini-D=0.1504\n",
      "Training epoch 24/200, 16.03, 6.21 loss = 40246248.00, Prec@10=0.0820 Recall@10=0.0823 NDCG@10=0.0825 Nov@10=3.7786 Gini-D=0.1472\n",
      "Training epoch 25/200, 15.91, 6.31 loss = 40236564.00, Prec@10=0.0812 Recall@10=0.0814 NDCG@10=0.0819 Nov@10=3.7797 Gini-D=0.1479\n",
      "Training epoch 26/200, 15.90, 6.24 loss = 40228200.00, Prec@10=0.0811 Recall@10=0.0814 NDCG@10=0.0816 Nov@10=3.7827 Gini-D=0.1454\n",
      "Training epoch 27/200, 15.73, 6.14 loss = 40220548.00, Prec@10=0.0794 Recall@10=0.0797 NDCG@10=0.0798 Nov@10=3.7862 Gini-D=0.1446\n",
      "Training epoch 28/200, 15.37, 6.05 loss = 40211344.00, Prec@10=0.0791 Recall@10=0.0794 NDCG@10=0.0795 Nov@10=3.7866 Gini-D=0.1442\n",
      "Training epoch 29/200, 16.29, 6.22 loss = 40204040.00, Prec@10=0.0783 Recall@10=0.0786 NDCG@10=0.0786 Nov@10=3.7975 Gini-D=0.1437\n",
      "Training epoch 30/200, 16.67, 6.21 loss = 40195892.00, Prec@10=0.0779 Recall@10=0.0782 NDCG@10=0.0782 Nov@10=3.8068 Gini-D=0.1435\n",
      "Training epoch 31/200, 15.97, 6.32 loss = 40188544.00, Prec@10=0.0773 Recall@10=0.0775 NDCG@10=0.0777 Nov@10=3.8093 Gini-D=0.1432\n",
      "Training epoch 32/200, 15.96, 6.15 loss = 40180688.00, Prec@10=0.0765 Recall@10=0.0768 NDCG@10=0.0768 Nov@10=3.8186 Gini-D=0.1421\n",
      "Training epoch 33/200, 16.38, 6.37 loss = 40173016.00, Prec@10=0.0758 Recall@10=0.0761 NDCG@10=0.0763 Nov@10=3.8318 Gini-D=0.1420\n",
      "Training epoch 34/200, 15.81, 6.28 loss = 40166196.00, Prec@10=0.0747 Recall@10=0.0750 NDCG@10=0.0749 Nov@10=3.8360 Gini-D=0.1405\n",
      "Training epoch 35/200, 15.50, 6.19 loss = 40158568.00, Prec@10=0.0748 Recall@10=0.0751 NDCG@10=0.0750 Nov@10=3.8485 Gini-D=0.1431\n",
      "Training epoch 36/200, 15.68, 6.30 loss = 40151420.00, Prec@10=0.0745 Recall@10=0.0748 NDCG@10=0.0749 Nov@10=3.8538 Gini-D=0.1413\n",
      "Training epoch 37/200, 15.76, 6.26 loss = 40143628.00, Prec@10=0.0740 Recall@10=0.0743 NDCG@10=0.0741 Nov@10=3.8731 Gini-D=0.1428\n",
      "Training epoch 38/200, 15.48, 6.24 loss = 40136700.00, Prec@10=0.0732 Recall@10=0.0735 NDCG@10=0.0735 Nov@10=3.8773 Gini-D=0.1426\n",
      "Training epoch 39/200, 15.66, 6.41 loss = 40130296.00, Prec@10=0.0730 Recall@10=0.0733 NDCG@10=0.0733 Nov@10=3.8812 Gini-D=0.1428\n",
      "Training epoch 40/200, 15.87, 6.32 loss = 40123480.00, Prec@10=0.0722 Recall@10=0.0725 NDCG@10=0.0723 Nov@10=3.9036 Gini-D=0.1445\n",
      "Training epoch 41/200, 15.58, 6.21 loss = 40116508.00, Prec@10=0.0724 Recall@10=0.0727 NDCG@10=0.0724 Nov@10=3.9105 Gini-D=0.1431\n",
      "Training epoch 42/200, 15.84, 6.22 loss = 40110160.00, Prec@10=0.0716 Recall@10=0.0719 NDCG@10=0.0718 Nov@10=3.9135 Gini-D=0.1436\n",
      "Training epoch 43/200, 15.33, 6.23 loss = 40103688.00, Prec@10=0.0722 Recall@10=0.0726 NDCG@10=0.0727 Nov@10=3.9282 Gini-D=0.1436\n",
      "Training epoch 44/200, 15.44, 6.06 loss = 40097732.00, Prec@10=0.0712 Recall@10=0.0715 NDCG@10=0.0714 Nov@10=3.9395 Gini-D=0.1458\n",
      "Training epoch 45/200, 15.08, 6.09 loss = 40091236.00, Prec@10=0.0706 Recall@10=0.0709 NDCG@10=0.0708 Nov@10=3.9533 Gini-D=0.1457\n",
      "Training epoch 46/200, 15.96, 6.40 loss = 40085052.00, Prec@10=0.0705 Recall@10=0.0708 NDCG@10=0.0708 Nov@10=3.9583 Gini-D=0.1454\n",
      "Training epoch 47/200, 15.46, 6.11 loss = 40078956.00, Prec@10=0.0701 Recall@10=0.0704 NDCG@10=0.0704 Nov@10=3.9626 Gini-D=0.1445\n",
      "Training epoch 48/200, 15.61, 6.09 loss = 40073288.00, Prec@10=0.0693 Recall@10=0.0696 NDCG@10=0.0693 Nov@10=3.9732 Gini-D=0.1451\n",
      "Training epoch 49/200, 15.77, 6.27 loss = 40067856.00, Prec@10=0.0698 Recall@10=0.0701 NDCG@10=0.0701 Nov@10=3.9939 Gini-D=0.1469\n",
      "Training epoch 50/200, 15.06, 6.06 loss = 40062088.00, Prec@10=0.0695 Recall@10=0.0698 NDCG@10=0.0701 Nov@10=3.9992 Gini-D=0.1453\n",
      "Training epoch 51/200, 15.25, 6.08 loss = 40056300.00, Prec@10=0.0682 Recall@10=0.0685 NDCG@10=0.0686 Nov@10=4.0077 Gini-D=0.1470\n",
      "Training epoch 52/200, 15.24, 6.07 loss = 40050984.00, Prec@10=0.0686 Recall@10=0.0689 NDCG@10=0.0688 Nov@10=4.0231 Gini-D=0.1469\n",
      "Training epoch 53/200, 15.70, 6.15 loss = 40045944.00, Prec@10=0.0678 Recall@10=0.0681 NDCG@10=0.0679 Nov@10=4.0279 Gini-D=0.1467\n",
      "Training epoch 54/200, 15.26, 6.08 loss = 40040344.00, Prec@10=0.0673 Recall@10=0.0676 NDCG@10=0.0678 Nov@10=4.0423 Gini-D=0.1460\n",
      "Training epoch 55/200, 14.83, 6.08 loss = 40035624.00, Prec@10=0.0672 Recall@10=0.0675 NDCG@10=0.0674 Nov@10=4.0496 Gini-D=0.1465\n",
      "Training epoch 56/200, 14.97, 6.06 loss = 40031036.00, Prec@10=0.0670 Recall@10=0.0673 NDCG@10=0.0672 Nov@10=4.0588 Gini-D=0.1476\n",
      "Training epoch 57/200, 15.88, 6.12 loss = 40026444.00, Prec@10=0.0672 Recall@10=0.0675 NDCG@10=0.0673 Nov@10=4.0761 Gini-D=0.1491\n",
      "Training epoch 58/200, 15.61, 6.08 loss = 40021476.00, Prec@10=0.0667 Recall@10=0.0670 NDCG@10=0.0670 Nov@10=4.0793 Gini-D=0.1479\n",
      "Training epoch 59/200, 15.01, 6.16 loss = 40016532.00, Prec@10=0.0662 Recall@10=0.0665 NDCG@10=0.0662 Nov@10=4.0881 Gini-D=0.1492\n",
      "Training epoch 60/200, 15.56, 6.26 loss = 40012344.00, Prec@10=0.0667 Recall@10=0.0670 NDCG@10=0.0671 Nov@10=4.0965 Gini-D=0.1491\n",
      "Early Stop Triggered...\n",
      "Training Finished.\n",
      "Best score at epoch 10] Prec@10 = 0.0907 Recall@10 = 0.0910 NDCG@10 = 0.0928 Nov@10 = 3.9061 Gini-D = 0.1712\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "epochs = 200\n",
    "best_epoch = -1\n",
    "best_score = None\n",
    "best_params = None\n",
    "patience = 50\n",
    "\n",
    "if len(list(model.parameters())) > 0:\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "else:\n",
    "    optimizer = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # train for an epoch\n",
    "    epoch_start = time.time()\n",
    "    loss = model.train_loop(dataset, optimizer, batch_size, verbose=False)\n",
    "    train_elapsed = time.time() - epoch_start\n",
    "\n",
    "    # evaluate\n",
    "    score = evaluator.evaluate(model, testing_batch_size)\n",
    "    epoch_elapsed = time.time() - epoch_start\n",
    "\n",
    "    score_str = ' '.join(['%s=%.4f' % (m, score[m]) for m in score])\n",
    "\n",
    "    print(f\"Training epoch {epoch}/{epochs}, {epoch_elapsed:.2f}, {train_elapsed:.2f} loss = {loss:.2f}, {score_str}\")\n",
    "\n",
    "    # update if ...\n",
    "    standard = 'NDCG@10'\n",
    "    if best_score is None or score[standard] >= best_score[standard]:\n",
    "        best_epoch = epoch\n",
    "        best_score = score\n",
    "        best_params = model.parameters()\n",
    "        endure = 0\n",
    "    else:\n",
    "        endure += 1\n",
    "        if early_stop and endure >= patience:\n",
    "            print('Early Stop Triggered...')\n",
    "            break\n",
    "        \n",
    "    writer.add_scalar('Loss/train', loss, epoch)\n",
    "\n",
    "print('Training Finished.')\n",
    "best_score_str = ' '.join(['%s = %.4f' % (k, best_score[k]) for k in best_score])\n",
    "print(f'Best score at epoch {best_epoch}] {best_score_str}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06193054",
   "metadata": {},
   "source": [
    "Since the training set is split 80/20 for each user's preference set, the evaluation metric will be calculated for the reconstructed data afer being corrupted on how many corrected preference (the 20% left) of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1b85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "tensor([[0., 0., 1.,  ..., 0., 0., 0.]])\n",
      "[18  9 20  2 15  4 21 17 16 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2q/tbcdmvhj22qfn57wnpc5cxlw0000gn/T/ipykernel_51596/1246735906.py:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)\n",
      "  user_ratings_tensor = torch.FloatTensor([np.array(dataset.train_matrix.toarray()[20])])\n"
     ]
    }
   ],
   "source": [
    "from utils import inference\n",
    "\n",
    "user_id = torch.LongTensor([20])\n",
    "print(user_id.shape)\n",
    "user_ratings_tensor = torch.FloatTensor([np.array(dataset.train_matrix.toarray()[20])])\n",
    "print(user_ratings_tensor)\n",
    "it = inference(model, user_id=user_id, user_ratings_tensor=user_ratings_tensor, apply_dropout=True)\n",
    "print(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356db41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "[15  9 19  2 14  4 21 18 17 16]\n"
     ]
    }
   ],
   "source": [
    "from utils import inference\n",
    "\n",
    "user_id = torch.LongTensor([500])\n",
    "print(user_id.shape)\n",
    "user_ratings_tensor = torch.FloatTensor([np.array(dataset.train_matrix.toarray()[20])])\n",
    "it = inference(model, user_id=user_id, user_ratings_tensor=user_ratings_tensor, apply_dropout=True)\n",
    "print(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c08f7b",
   "metadata": {},
   "source": [
    "The meaning of sparse matrix is to has many zeros and non-zeros values at the index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
